### 实验三：基于Flink SQL的流式数据查询

#### 实验目标：腾讯云租借1台服务器，安装单机版Flink

#### 编写demo程序，使用maven编译Flink SQL程序

#### 租借三台服务器，搭建k8s容器管理平台，并提交编译好的flink SQL程序

- 第七周：完成单机部署，制作镜像

- 第八周：完成集群部署，Flink作业提交

- 第九周：重复整个流程

  - 单台服务器租借，JAVA安装， Flink安装，环境变量配置，镜像制作

  - 租借三台服务器 K8s集群启动，Maven安装，编译Flink作业，提交Flink作业

- 流处理：数据以连续的流的形式到达，处理系统会立即对新到达的数据进行处理。
  - 三个等级：
    - at most once
    - at least once: ack()
    - exactly once: offset，用滑动指针直线，如处理数据1，2，4则指针回退，处理数据3

批处理：讲数据收集起来，积累到一定最后作为一个批次进行处理

```shell
# jre java运行环境，jdk java开发工具包development kit
sudo apt-get install openjdk-8-jre openjdk-8-jdk

# 写入环境变量
vim~/.bashrc
# 第一行添加
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
# 应用
source ~/.bashrc
# 列出java版本验证
java -version

# 安装flink
wget https://archive.apache.org/dist/flink/flink-1.16.0/flink-1.16.0-bin-scala_2.12.tgz
# 解压
sudo tar -zxvf flink-1.16.0-bin-scala_2.12.tgz -C /usr/local
# 改名
cd /usr/local
sudo mv flink-1.16.0 flink
# 改文件所有者，所属组
sudo chown -R ubuntu:root flink

# 添加环境变量
vim ~/.bashrc
export FLINK_HOME=/usr/local/flink
export PATH=$FLINK_HOME/bin:$PATH
source ~/.bashrc
# 制作镜像

# 启动单节点集群
cd flink/bin
./start-cluster.sh
jps
# 看到3个结点
# 放开8081端口

# 提交一个flink作业
flink run /usr/local/flink/examples/batch/WordCount.jar
```

第八周内容

```shell
# 到/usr/local/flink/conf文件夹修改flink-conf.yaml配置文件
# 将Rest & web frontend中的rest.address和rest.bind-address改为0.0.0.0
# 启动集群
./bin/start-cluster.sh
# 尝试本地打开网页，会打印出网页内容
curl http://[公网ip]:8081
# 也可以打开网页

# 下载maven
wget https://dlcdn.apache.org/maven/maven-3/3.9.4/binaries/apache-maven-3.9.4-bin.zip

# 解压到/usr/local目录下，改名为maven，修改为root用户组下的ubuntu用户
sudo unzip apache-maven-3.9.4-bin.zip -d /usr/local
cd /usr/local
sudo mv apache-maven-3.9.4 maven
sudo chown -R ubuntu:root maven
cd ~

# -p当父目录不存在时，创建父目录
mkdir flinkapp
mkdir -p flinkapp/src/main/java
# 创建三个java代码WordCount.java WordCountTokenizer.java WordCountData.java
cd ~/flinkapp
# 创建配置文件
vim pom.xml
# 搜索文件和目录
find .
# 在当前目录下，使用maven进行打包编译
~/flinkapp: /usr/local/maven/bin/mvn package
# 添加环境变量后，直接mvn package
# 提交作业
/usr/local/flink/bin/flink run --class cn.edu.shu.WordCount ~/flinkapp/target/wordcount-1.0.jar

# 可以在webui中的taskmanager中看到运行结果

# 新建文件夹写SQL
mkdir tableapp
mkdir -p tableapp/src/main/java
vim tableapp/src/main/java/InputFromFileDemo.java
cd ~/tableapp
vim pom.xml # 将pom2.xml粘贴上去

# 新建stockprice.csv，并提交作业
~:vim stockprice.csv
stock1,123
stock2,246

flink run --class cn.edu.shu.InputFromFileDemo ~/tableapp/target/inputfromfiledemo-1.0.jar

# 停止集群，保存镜像
/usr/local/flink/bin/stop-cluster.sh
```

### 第九周

期末报告可以跑大数据集6千多万行。

#### 实验报告要求

- 简单介绍实验输入的命令行：
  - 如maven编译，集群启动命令等

- 5-6页，flink环境安装截图：
  - java--version;
  - 安装完flink登录8081端口网页；
  - 提交SQL代码；

- 这道题的flink语句嵌入式SQL代码截图

- 前50行结果截图（medium数据集即可）

#### 大数据集思路（做出来就满分）

- out(A) U out(B), out(A) ^ out(B)

| out(A) U out(B) | +    | out(A) ^ out(B) | =    | out(A) | +    | out(B) |
| --------------- | ---- | --------------- | ---- | ------ | ---- | ------ |
| A,B网站的并     | +    | A,B网站的交集   | =    | A      | +    | B      |

- select ……

  from R1, R2

  where R1(A) = R2(A)

  可以改为

  select ……

  from R1(A) join R2(A)

- 可预先处理，删除重复行，不允许使用limit和top

- 可用嵌入式SQL分布编写,使用k8s管理平台分布多个结点

- k8s平台管理使用方式：https://nightlies.apache.org/flink/flink-kubernetes-operator-docs-release-1.11/docs/try-flink-kubernetes-operator/quick-start/

#### 有用操作记录

```shell
# 将文件传到本地
scp flink-conf.yaml "winner@59.79.2.198:D:\\"

# 输出csv前10行
head -n 10 your_file.csv
# 进入容器
kubectl exec -it largejob-7fbc68c96d-cm7qm -- /bin/sh

# 放开监听端口
kubectl port-forward svc/largejob-rest 8081 --address 0.0.0.0

kubectl logs -f deploy/largejob

kubectl delete -f basic.yaml
kubectl delete flinkdeployment/largejob

# 查看pod运行的机器
kubectl get pods -o wide
# 显示节点标签
kubectl get nodes --show-labels

# 移除master污点限制
kubectl taint node vm-0-9-ubuntu node-role.kubernetes.io/master:NoSchedule-
# 为节点打标签
kubectl label nodes vm-0-14-ubuntu flink-role=jobmanager

# 强制停止operator
kubectl delete deployment flink-kubernetes-operator
# 卸载operator
helm list -A | grep flink-kubernetes-operator
helm uninstall flink-kubernetes-operator -n default
# 重新生成join命令
kubeadm token create --print-join-command
# 删除节点
kubectl delete node vm-0-16-ubuntu
```

```shell
# 先在主节点上启动集群（address切换成自己的内网ip）
sudo kubeadm init --apiserver-advertise-address=172.19.0.7 --image-repository registry.aliyuncs.com/google_containers --service-cidr=10.96.0.0/12  --pod-network-cidr=10.244.0.0/16

# 配置 kubectl 的客户端访问权限
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# 下载网络插件
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

# 创建一个yaml文件flink-job.yaml，用于描述flink作业在k8s中的部署配置
```

#### 实验步骤

```shell
# master启动k8s集群
sudo kubeadm init --apiserver-advertise-address=172.19.0.2 --image-repository registry.aliyuncs.com/google_containers --service-cidr=10.96.0.0/12  --pod-network-cidr=10.244.0.0/16

# 如果集群启动失败，通过以下命令重置
sudo kubeadm reset

# slave加入集群（类似于下面）
sudo kubeadm join 172.29.0.4:6443 --token fotxct.cgaqberwypfk3xgz \
--discovery-token-ca-cert-hash sha256:31ea2841587a4338dfcd9312b1bb6c8eabe448afcbad6bd2188392ca7a9289c3

# 创建yaml任务
vim basic.yaml
```

- basic.yaml文件

```yaml
apiVersion: flink.apache.org/v1beta1
kind: FlinkDeployment
metadata:
  namespace: default
  name: largejob
spec:
  image: flink:1.16
  flinkVersion: v1_16
  flinkConfiguration:
    taskmanager.numberOfTaskSlots: "12" # 每个taskmanager有16个task slot
  serviceAccount: flink
  jobManager:
    resource:
      memory: "4096m" # 每个jobmanager分配4G内存
      cpu: 2
    podTemplate:
      spec:
        # nodeSelector:
          # flink-role: jobmanager
        tolerations:
          - key: "node-role.kubernetes.io/master"
            operator: "Exists"
            effect: "NoSchedule"
        containers:
          - name: flink-main-container
            volumeMounts:
              - name: my-jar
                mountPath: /opt/flink/largejob
        volumes:
          - name: my-jar
            hostPath:
              path: /home/ubuntu/tableapp/upload # 本地JAR所在目录
              type: Directory
  taskManager:
    resource:
      memory: "51200m"
      cpu: 12 # 每个taskmanager分配16个CPU
    replicas: 3 # 启动2个taskmanager pod，调度到2个节点
    podTemplate:
      spec:
        nodeSelector:
          flink-role: taskmanager
        tolerations:
          - key: "node-role.kubernetes.io/master"
            operator: "Exists"
            effect: "NoSchedule"
        containers:
          - name: flink-main-container
            volumeMounts:
              - name: my-jar
                mountPath: /opt/flink/largejob
        volumes:
          - name: my-jar
            hostPath:
              path: /home/ubuntu/tableapp/upload # 本地JAR所在目录
              type: Directory
  job:
    jarURI: local:///opt/flink/largejob/inputfromfiledemo-1.0.jar
    entryClass: cn.edu.shu.large_result # 这里填写你的主类全名
    parallelism: 36

```

- java代码编译好后，将jar包和数据集移到同一目录/home/ubuntu/upload下,修改目录及权限为777，并复制到所有节点相同目录下

```shell
# 修改目录权限
sudo chmod -R 777 upload
# k8s下提交任务
kubectl create -f basic.yaml
# jobmanager节点暴露端口给外来用户访问webui，bacis-example改为name:largejob
kubectl port-forward svc/largejob-rest 8081 --address 0.0.0.0
# 查看作业运行状态
kubectl logs -f deploy/largejob
# 查看flink容器状态
kubectl get pods
# 删除任务
kubectl delete -f basic.yaml
# 进入容器
kubectl exec -it largejob-7fbc68c96d-cm7qm -- /bin/sh
```

- 最终结果应在本地/home/ubuntu/tableapp/upload下

